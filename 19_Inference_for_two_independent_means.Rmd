---
title: "19. Inference for two independent means"
author: "Put your name here"
date: "Put the date here"
output:
    html_notebook:
        toc: yes
        toc_float: yes
---

<!-- Please don't mess with the next few lines! -->
<style>h5{font-size:2em;color:#0000FF}h6{font-size:1.5em;color:#0000FF}div.answer{margin-left:5%;border:1px solid #0000FF;border-left-width:10px;padding:25px} div.summary{background-color:rgba(30,144,255,0.1);border:3px double #0000FF;padding:25px}</style>`r options(scipen=999)`<p style="color:#ffffff">`r intToUtf8(c(49,46,52))`</p>
<!-- Please don't mess with the previous few lines! -->

<div class = "summary">
### Functions introduced in this module:
`diffmean`
</div>


## Introduction

If we have a numerical variable and a categorical variable with two categories, we can think of the numerical variable as response and the categorical variable as explanatory. The idea is that the two categories sort your numerical data into two groups which can be compared. Assuming the two groups are independent of each other, we can use them as samples of two larger populations. This leads to inference to decide if the difference between the means of the two groups is statistically significant and then estimate the difference between the means of the two populations represented. The relevant hypothesis test is called a two-sample t test (or Welch's t test, to be specific).


## Load packages

We load the standard `mosaic` package as well as the `MASS` for the `cabbages` data. The `broom` package gives us tidy output.

```{r, warning = FALSE, message = FALSE}
library(MASS)
library(broom)
library(mosaic)
```


## Research question

We have data on two cultivars of cabbage called "c39" and "c52". Is there a difference in weight of the cabbage heads between these two varieties?


## Every day I'm shuffling

Whenever there are two groups, the obvious null hypothesis is that there is no difference between them.

Consider the cultivar types c39 and c52. If there were truly no difference in weight between these cultivars, then it shouldn't matter if we know the cultivar or not. It becomes irrelevant under the assumption of the null.

We can simulate this assumption by shuffling the names of the cultivars. More concretely, we can randomly assign cultivar labels to each head of cabbage and then calculate the average weight in each cultivar group. Since the cultivar labels are random, there's no reason to expect a difference between the two average weights other than random fluctuations due to sampling variability.

The mean weights in each sample (the c39 and c52 cultivars) can be found using the `mean` command and the tilde notation. The following command should be read aloud as "calculate the mean head weight *by* cultivar type," or "*grouped by* cultivar type."

```{r}
mean(HeadWt ~ Cult, data = cabbages)
```

The difference between the means is calculated with the `diffmean` command. We'll store this result as `obs_diff` for "observed difference".

```{r}
obs_diff <- diffmean(HeadWt ~ Cult, data = cabbages)
obs_diff
```

(Note that the order of subtraction here is c52 minus c39. This is significant because the `t.test` command we use later will perform this subtraction in the other direction, so pay close attention.)

This is the list of cultivars in the actual data:

```{r}
cabbages$Cult
```

This is what happens when we `shuffle` them.

```{r}
set.seed(1729)
shuffle(cabbages$Cult)
```

Now we can calculate the group means and their difference for shuffled data. Let's do it few times.

```{r}
set.seed(1729)
diffmean(HeadWt ~ shuffle(Cult), data = cabbages)
diffmean(HeadWt ~ shuffle(Cult), data = cabbages)
diffmean(HeadWt ~ shuffle(Cult), data = cabbages)
```

We use the `do` command to do this a bunch of times and graph the results along with our observed difference.

```{r}
set.seed(1729)
sims <- do(2000) * diffmean(HeadWt ~ shuffle(Cult),
                            data = cabbages)
```

```{r}
ggplot(sims, aes(x = diffmean)) +
    geom_histogram(binwidth = 0.1, boundary = 0) +
    geom_vline(xintercept = obs_diff, color = "blue")
```

No surprise that this histogram looks nearly normal, centered at zero: the simulation is working under the assumption of the null hypothesis of no difference between the groups.

Our observed difference (from the sampled data) is quite far out into the tail of this simulated sampling distribution, so it appears that our actual data would be unlikely due to pure chance alone if the null hypothesis were true.

We can even find a P-value by calculating how many of our sampled values are as extreme or more extreme than the observed data difference. The command below accomplishes this by calculating the percentage of samples in the left tail and then multiplying by 2 to make it a two-sided test. (It's two-sided because we didn't have any preconceptions about which cultivar would be heavier.)

```{r}
2 * prop(sims$diffmean <= obs_diff)
```

Indeed, this is a small P-value.


## The sampling distribution model

In the previous section, we simulated the sampling distribution under the assumption of a null hypothesis of no difference between the groups. It certainly looked like a normal model, but which normal model? The center is obviously zero, but what about the standard deviation?

Let's assume that both groups come from populations that are normally distributed with normal models $N(\mu_{1}, \sigma_{1})$ and $N(\mu_{2}, \sigma_{2})$. If we take samples of size $n_{1}$ from group 1 and $n_{2}$ from group 2, some fancy math shows that the distribution of the differences between sample means is

$$N\left(\mu_{1} - \mu_{2}, \sqrt{\frac{\sigma_{1}^{2}}{n_{1}} + \frac{\sigma_{2}^{2}}{n_{2}}}\right).$$

Under the assumption of the null, the difference of the means is zero ($\mu_{1} - \mu_{2} =  0$). Unfortunately, though, we make no assumption on the standard deviations. It should be clear that the only solution is to substitute the sample standard deviations $s_{1}$ and $s_{2}$ for the population standard deviations $\sigma_{1}$ and $\sigma_{2}$.^[When we were testing two proportions with categorical data, one option (described in an optional appendix in that module) was to pool the data. With numerical data, we can calculate a pooled mean, but that doesn't help with the unknown standard deviations. Nothing in the null hypothesis suggests that the standard deviations of the two groups should be the same. In the extremely rare situation in which one can assume equal standard deviations in the two groups, then there is a way to run a pooled t test. But this "extra" assumption of equal standard deviations is typically questionable.]

$$SE = \sqrt{\frac{s_{1}^{2}}{n_{1}} + \frac{s_{2}^{2}}{n_{2}}}.$$

However, $s_{1}$ and $s_{2}$ are not perfect estimates of $\sigma_{1}$ and $\sigma_{2}$; they are subject to sampling variability too. This extra variability means that a normal model is no longer appropriate as the sampling distribution model.

In the one-sample case, a Student t model with $df = n - 1$ was the right choice. In the two-sample case, we don't know the right answer. And I don't mean that we haven't learned it yet in our stats class. I mean, statisticians have not found a formula for the correct sampling distribution. It is a famous unsolved problem, called the Behrens-Fisher problem.

Several researchers have proposed solutions that are "close" though. One compelling one is called "Welch's t test". Welch showed that even though it's not quite right, a Student t model is very close as long as you pick the degrees of freedom carefully. Unfortunately, the way to compute the right degrees of freedom is crazy complicated. Fortunately, R is good at crazy complicated computations. The `t.test` command uses the Welch's t test by default when there are two groups.

Let's go through the full rubric using the cabbage example.


## Exploratory data analysis

### Use data documentation (help files, code books, Google, etc.), the `str` command, and other summary functions to understand the data.

[You should type `?cabbages` at the Console to read the help file.]

```{r}
cabbages
```

```{r}
str(cabbages)
```

We can also use `favstats` to see summary statistics of head weight for each cultivar using the tilde notation.

```{r}
favstats(HeadWt ~ Cult, data = cabbages)
```

### Prepare the data for analysis.

The cultivar variable `Cult` is already a factor variable, as it should be.

### Make tables or plots to explore the data visually.

How many cabbages of each cultivar type do we have?

```{r}
tally(~ Cult, data = cabbages)
```

With a numerical response variable and a categorical explanatory variable, there are two useful plots: a side-by-side boxplot and a stacked histogram.

```{r}
ggplot(cabbages, aes(y = HeadWt, x = Cult)) +
    geom_boxplot()
```

```{r}
ggplot(cabbages, aes(x = HeadWt)) +
    geom_histogram(binwidth = 0.5, boundary = 1) +
    facet_grid(Cult ~ .)
```

The histogram of the c39 group looks reasonably normal and the c52 group may be somewhat skewed to the right, although it's a bit hard to tell with a sample size of 30 in each group. Here are the QQ plots to give us another way to ascertain normality of the data.

```{r}
ggplot(cabbages, aes(sample = HeadWt)) +
    geom_qq() +
    geom_qq_line() +
    facet_grid(Cult ~ .)
```

Any deviation from normality looks minor.

Commentary: The boxplots and histograms show why statistical inference is so important. It's clear that there is some difference between the two groups, but it's not obvious if that difference will turn out to be statistically significant. There appears to be a lot of variability in both groups, and both groups have a fair number of lighter and heavier cabbage heads.


## Hypotheses

### Identify the sample (or samples) and a reasonable population (or populations) of interest.

The samples consist of 30 cabbages from the c39 group and 30 cabbages from the c52 group. The populations are all cabbages of variety c39 and all cabbages of variety c52.

### Express the null and alternative hypotheses as contextually meaningful full sentences.

$H_{0}:$ There is no difference in the head weight of c39 cabbages and c52 cabbages.

$H_{A}:$ There is a difference in the head weight of c39 cabbages and c52 cabbages.

### Express the null and alternative hypotheses in symbols (when possible).

$H_{0}: \mu_{c39} - \mu_{c52} = 0$

$H_{A}: \mu_{c39} - \mu_{c52} \neq 0$

Commentary: Pay close attention to the order of subtraction. It's easiest to make your hypotheses match the order of the `t.test` command we use later in the rubric. **It is the oppposite of the `diffmean` command!** How do we know? Let's run the `t.test` command a little early and look at the output.

```{r}
cabbage_test <- t.test(HeadWt ~ Cult, data = cabbages)
cabbage_test_tidy <- tidy(cabbage_test)
cabbage_test_tidy
```

The `estimate` is positive, obtained by subtracting `estimate1` minus `estimate2`. Looking back to the mean of both groups that we calculated with the `mean` command, we can see that `estimate1` corresponds to the c39 group and `estimate2` corresponds to the c52 group.


## Model

### Identify the sampling distribution model.

We use a t model. Since we ran the `t.test` command already, we can see the degrees of freedom:

```{r}
cabbage_test_tidy$parameter
```

So we will use a t model with `r cabbage_test_tidy$parameter` degrees of freedom.

Commentary: For Welch's t test, the degrees of freedom won't usually be a whole number. Be sure you understand that the formula is no longer $df = n - 1$. That doesn't even make any sense as there isn't a single $n$ in a *two*-sample test.

### Check the relevant conditions to ensure that model assumptions are met.

* Random (for both groups)
    - We have no information at all about these cabbages. We hope that the 30 we have of each kind are representative of all cabbages from the two cultivars.

* 10% (for both groups)
    - 30 is less than 10% of all c39 cabbages and 30 is less than 10% of all c52 cabbages.
    
* Nearly normal (for both groups)
    - Since the sample sizes are 30 in each group, we meet the condition.


## Mechanics

### Compute the test statistic.

```{r}
t1 <- cabbage_test_tidy$statistic
t1
```

### Report the test statistic in context (when possible).

The t score is `r t1`. The sample difference in cabbage weights is about 3 standard errors higher than the null value of zero.

### Plot the null distribution.

```{r}
pdist("t", df = cabbage_test_tidy$parameter,
      q = c(-t1, t1),
      invisible = TRUE)
```

### Calculate the P-value.

```{r}
P1 <- cabbage_test_tidy$p.value
P1
```

### Interpret the P-value as a probability given the null.

The P-value is `r P1`. If there were no difference in the mean head weights of the two cultivars, there would be a `r 100 * P1`% chance of seeing data at least as extreme as what we saw.


## Conclusion

### State the statistical conclusion.

We reject the null hypothesis.

### State (but do not overstate) a contextually meaningful conclusion.

We have sufficient evidence that there is a difference in the head weight of c39 cabbages and c52 cabbages.

### Identify the possibility of either a Type I or Type II error and state what making such an error means in the context of the hypotheses.

If we've made a Type I error, then that means that there might be no difference in the head weight of c39 cabbages and c52 cabbages, but we got some unusual samples that showed a difference.


## Confidence interval

### Check the relevant conditions to ensure that model assumptions are met.

There are no additional conditions to check.

### Calculate the confidence interval.

```{r}
cabbage_test_tidy$conf.low
```

```{r}
cabbage_test_tidy$conf.high
```

### State (but do not overstate) a contextually meaningful interpretation.

We are 95% confident that the true difference in mean head weight between c39 and c52 cabbages is captured in the interval (`r cabbage_test_tidy$conf.low` kg, `r cabbage_test_tidy$conf.high` kg). We obtained this by subtracting c39 minus c52.

Commentary: Don't forget that any time we find a number that represents a difference, we have to be clear in the conclusion about the direction of subtraction. Otherwise, we have no idea how to interpret positive and negative values. (Does this interval mean that c39 heads or c52 heads are heavier? Since we calculated c39 minus c52 and these numbers are positive, that means that c39 heads are, on average, heavier.)

### If running a two-sided test, explain how the confidence interval reinforces the conclusion of the hypothesis test.

Since zero is not contained in the confidence interval, zero is not a plausible value for the true difference in head weights between the two cultivars.


## Inference using summary statistics

In the previous example, we had access to the actual data frame. In some situations, you are not given the data; rather, all you have are summary statistics about the data. This certainly happens with homework problems from a textbook, but it can happen in "real life" too. If you're reading a research article, you will rarely have access to the original data used in the analysis. All you can see is what the researchers report in their paper.

For a two-sample t test, often you have nothing but the sample sizes $n_{1}$ and $n_{2}$, the sample means $\bar{y}_{1}$ and $\bar{y}_{2}$, and the sample standard deviations $s_{1}$ and $s_{2}$.

Unlike the `binom.test` or `prop.test` commands that allow you to use either the raw data or summary statistics, the `t.test` command does not allow this. Instead, you have to calculate the t score directly and use `pdist` to get the P-value.

For example, suppose you are told only that for the first group $n_{1} = 48$, $\bar{y}_{1} = 8.8$, and $s_{1} = 2.1$; and for the second group $n_{2} = 54$, $\bar{y}_{2} = 10.4$, and $s_{2} = 3.1$.

Using the formula for the standard error that appeared earlier in the module, here's the t score:

```{r}
t2 <- (8.8 - 10.4)/sqrt(2.1^2/48 + 3.1^2/54)
t2
```

The trouble we face is that the degrees of freedom will be complicated. In the event that the degrees of freedom are reported, we're good. For example, suppose we're told that there are 93.7 degrees of freedom. If that's the case, the P-value can be calculated: 

```{r}
P2a <- 2 * pdist("t", df = 93.7, q = t2, plot = FALSE)
P2a
```

If you don't have the degrees of freedom, you could google the Welch-Satterthwaite formula and plug in all the necessary values to calculate degrees of freedom for yourself.^[This is painful.] Or, another common recommendation is to use a conservative estimate for the degrees of freedom by choosing the *smaller* of $n_{1} - 1$ or $n_{2} - 1$. If we didn't know the degrees of freedom for the above example, we could use 47 degrees of freedom ($48 - 1$) and get the following P-value:

```{r}
P2b  <- 2 * pdist("t", df = 47, q = t2,  plot = FALSE)
P2b
```

While a bit larger than the "correct" P-value, it's still plenty small. Either way we would reject the null.

Be careful: with only summary statistics, we can't do any exploratory data analysis, so it may be impossible to check conditions. The only condition we have to check with the raw data is the nearly normal condition. In this example, though, since both samples are larger than 30, we're not too worried.


## Your turn

Continue to use the `cabbage` data set. This time, explore the ascorbic acid (vitamin C) content of each of the two cultivars.

The rubric outline is reproduced below. You may refer to the worked example above and modify it accordingly. Remember to strip out all the commentary. That is just exposition for your benefit in understanding the steps, but is not meant to form part of the formal inference process.

Another word of warning: the copy/paste process is not a substitute for your brain. You will often need to modify more than just the names of the data frames and variables to adapt the worked examples to your own work. Do not blindly copy and paste code without understanding what it does. And you should **never** copy and paste text. All the sentences and paragraphs you write are expressions of your own analysis. They must reflect your own understanding of the inferential process.

**Also, so that your answers here don't mess up the code chunks above, use new variable names everywhere.**

You should run the t test earlier than the Mechanics section where you would normally run it. Instead, run that code in the "Identify the sampling distribution model" section so that you can report the degrees of freedom for the t model.

##### Exploratory data analysis

###### Use data documentation (help files, code books, Google, etc.), the `str` command, and other summary functions to understand the data.

<div class = "answer">

```{r}
# Add code here to understand the data.
```

</div>

###### Prepare the data for analysis. [Not always necessary.]

<div class = "answer">

```{r}
# Add code here to prepare the data for analysis.
```

</div>

###### Make tables or plots to explore the data visually.

<div class = "answer">

```{r}
# Add code here to make tables or plots.
```

</div>


##### Hypotheses

###### Identify the sample (or samples) and a reasonable population (or populations) of interest.

<div class = "answer">

Please write up your answer here.

</div>

###### Express the null and alternative hypotheses as contextually meaningful full sentences.

<div class = "answer">

$H_{0}:$ Null hypothesis goes here.

$H_{A}:$ Alternative hypothesis goes here.

</div>

###### Express the null and alternative hypotheses in symbols (when possible).

<div class = "answer">

$H_{0}: math$

$H_{A}: math$

</div>


##### Model

###### Identify the sampling distribution model.

<div class = "answer">

Please write up your answer here.

</div>

###### Check the relevant conditions to ensure that model assumptions are met.

<div class = "answer">

Please write up your answer here. (Some conditions may require R code as well.)

</div>


##### Mechanics

###### Compute the test statistic.

<div class = "answer">

```{r}
# Add code here to compute the test statistic.
```

</div>

###### Report the test statistic in context (when possible).

<div class = "answer">

Please write up your answer here.

</div>

###### Plot the null distribution.

<div class = "answer">

```{r}
# Add code here to plot the null distribution.
```

</div>

###### Calculate the P-value.

<div class = "answer">

```{r}
# Add code here to calculate the P-value.
```

</div>

###### Interpret the P-value as a probability given the null.

<div class = "answer">

Please write up your answer here.

</div>


##### Conclusion

###### State the statistical conclusion.

<div class = "answer">

Please write up your answer here.

</div>

###### State (but do not overstate) a contextually meaningful conclusion.

<div class = "answer">

Please write up your answer here.

</div>

###### Identify the possibility of either a Type I or Type II error and state what making such an error means in the context of the hypotheses.

<div class = "answer">

Please write up your answer here.

</div>


##### Confidence interval

###### Check the relevant conditions to ensure that model assumptions are met.

<div class = "answer">

Please write up your answer here. (Some conditions may require R code as well.)

</div>

###### Calculate the confidence interval.

<div class = "answer">

```{r}
# Add code here to calculate the confidence interval.
```

</div>

###### State (but do not overstate) a contextually meaningful interpretation.

<div class = "answer">

Please write up your answer here.

</div>

###### If running a two-sided test, explain how the confidence interval reinforces the conclusion of the hypothesis test.

<div class = "answer">

Please write up your answer here.

</div>
