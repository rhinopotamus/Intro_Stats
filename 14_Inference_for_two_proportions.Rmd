---
title: "14. Inference for two proportions"
author: "Put your name here"
date: "Put the date here"
output:
    html_notebook:
        toc: yes
        toc_float: yes
---

<!-- Please don't mess with the next few lines! -->
<style>h5{font-size:2em;color:#0000FF}h6{font-size:1.5em;color:#0000FF}div.answer{margin-left:5%;border:1px solid #0000FF;border-left-width:10px;padding:25px} div.summary{background-color:rgba(30,144,255,0.1);border:3px double #0000FF;padding:25px}</style>`r options(scipen=999)`<p style="color:#ffffff">`r intToUtf8(c(49,46,52))`</p>
<!-- Please don't mess with the previous few lines! -->

<div class = "summary">
### Functions introduced in this module:
No new R functions are introduced here.
</div>


## Introduction

In this module, we revisit the idea of inference for two proportions, but this time using a normal model as the sampling distribution model.


## Load packages

We load the standard `mosaic` package as well as the `MASS` package for the `Melanoma` data. The `broom` package gives us tidy output.

```{r, warning = FALSE, message = FALSE}
library(MASS)
library(broom)
library(mosaic)
```


## Research question

In an earlier module, we used the data set `Melanoma` from the `MASS` package to explore the possibility of a sex bias among patients with melanoma. A related question is whether male or females are more likely to die from melanoma. In this case, we are thinking of `status` as the response variable and `sex` as the explanatory variable.


## The sampling distribution model for two proportions

When we simulated using shuffling, it looked like the simulated sampling distribution was roughly normal. Therefore, we should be able to use a normal model in place of simulation when we want to perform statistical inference.

The question is, "Which normal model?" In other words, what is the mean and standard deviation we should use?

Since we have two groups, let's call the true proportion of success $p_{1}$ for group 1 and $p_{2}$ for group 2. Therefore, the true difference between groups 1 and 2 in the population is $p_{1} - p_{2}$. If we sample repeatedly from groups 1 and 2 and form many sample differences $\hat{p}_{1} - \hat{p}_{2}$, we should expect most of the values $\hat{p}_{1} - \hat{p}_{2}$ to be close to the true difference $p_{1} - p_{2}$. In other words, the sampling distribution is centered at a mean of $p_{1} - p_{2}$.

What about the standard error? This is much more technical and complicated. Here is the formula, whose derivation is outside the scope of the course:

$$\sqrt{\frac{p_{1} (1 - p_{1})}{n_{1}} + \frac{p_{2} (1 - p_{2})}{n_{2}}}.$$

So the somewhat complicated normal model is

$$N\left( p_{1} - p_{2}, \sqrt{\frac{p_{1} (1 - p_{1})}{n_{1}} + \frac{p_{2} (1 - p_{2})}{n_{2}}} \right).$$

When we ran hypothesis tests for one proportion, the true proportion $p$ was assumed to be known, set equal to some null value. Therefore, we could calculate the standard error $\sqrt{\frac{p(1 - p)}{n}}$ under the assumption of the null.

We also have a null hypothesis for two proportions. When comparing two groups, the default assumption is that the two groups are the same. This translates into the mathematical statement $p_{1} - p_{2} = 0$ (i.e., there is no difference between $p_{1}$ and $p_{2}$).

But there is a problem here. Although we are assuming something about the difference $p_{1} - p_{2}$, we are not assuming anything about the actual values of $p_{1}$ and $p_{2}$. For example, both groups could be 0.3, or 0.6, or 0.92, or whatever, and the difference between the groups would still be zero.

Without values of $p_{1}$ and $p_{2}$, we cannot plug anything into the standard error formula above. One easy "cheat" is to just use the sample values $\hat{p}_{1}$ and $\hat{p}_{2}$:

$$SE = \sqrt{\frac{\hat{p}_{1} (1 - \hat{p}_{1})}{n_{1}} + \frac{\hat{p}_{2} (1 - \hat{p}_{2})}{n_{2}}}.$$

There is a more sophisticated way to address this called "pooling". This more advanced concept is covered in an [optional appendix](#pooling) to this module.


## Inference for two proportions

Below is a fully-worked example of inference (hypothesis test and confidence interval) for two proportions. When you work your own example, you can thoughtfully copy and paste the R code, making changes as necessary.

The example below will pause frequently for commentary on the steps, especially where their execution will be different from what you've seen before when you used simulation. When it's your turn to work through another example on your own, you should follow the outline of the rubric, but you should **not** copy and paste the commentary that accompanies it.


## Exploratory data analysis

### Use data documentation (help files, code books, Google, etc.), the `str` command, and other summary functions to understand the data.

[Type `?Melanoma` at the Console to read the help file.]

```{r}
Melanoma
```


```{r}
str(Melanoma)
```

### Prepare the data for analysis.

The two variables of interest are `status` and `sex`. We are considering them as categorical variables, but they are recorded numerically in the data frame. We convert them to proper factor variables and put them in their own data frame using the help file to identify the levels and labels we need.

There is a minor hitch with `status`. The help file shows three categories: 1. died from melanoma, 2. alive, 3. dead from other causes. For two-proportion inference, it would be better to have two categories only, a success category and a failure category. Since our research question asks about deaths due to melanoma, the "success" condition is the one numbered 1 in the help file, "died from melanoma". That means we need to combine the other two categories into a single failure category. Perhaps we should call it "other". You can accomplish this by simply repeating the "other" label more than once.

```{r}
status <- factor(Melanoma$status,
                 levels = c(1, 2, 3),
                 labels = c("died from melanoma",
                            "other", "other"))
sex <- factor(Melanoma$sex, levels = c(0, 1),
              labels = c("female", "male"))
status_sex <- data.frame(status, sex)
status_sex
```

### Make tables or plots to explore the data visually.

As these are two categorical variables, we should look at a contingency table. The variable `status` is response and `sex` is explanatory.

```{r}
tally(status ~ sex, data = status_sex, margins = TRUE)
```

```{r}
tally(status ~ sex, data = status_sex,
      margins = TRUE, format = "percent")
```

Commentary: You can see why column percentages are necessary in a contingency table. There are 28 females and 29 males who died from melanoma, almost a tie. However, there are more females (126) than there are males (79) who have melanoma in this data set. So the *proportion* of males who died from melanoma is quite a bit larger.

    
## Hypotheses

### Identify the sample (or samples) and a reasonable population (or populations) of interest.

There are two samples: 126 female patients and 79 male patients in Denmark with malignant melanoma. In order for these samples to be representative of their respective populations, we should probably restrict our conclusions to the population of all females and males in Denmark with malignant melanoma, although we might be able to make the case that these females and males could be representative of people in other countries who have malignant melanoma.

### Express the null and alternative hypotheses as contextually meaningful full sentences.

$H_{0}:$ There is no difference between the rate at which women and men in Denmark die from malignant melanoma.

$H_{A}:$ There is a difference between the rate at which women and men in Denmark die from malignant melanoma.

### Express the null and alternative hypotheses in symbols (when possible).

$H_{0}: p_{died, F} - p_{died, M} = 0$

$H_{A}: p_{died, F} - p_{died, M} \neq 0$

Commentary: The order in which you subtract is irrelevant to the inferential process. However, you should be sure that any future steps respect the order you choose here. A good bet is to look back to when you made the factor variables. The first condition listed in the labels of your explanatory variable is going to be the one that gets processed first by the `prop.test` function. In the variable `sex`, we listed "female" first. Therefore, it's safest to subtract $p_{died, F} - p_{died, M}$.


## Model

### Identify the sampling distribution model.

We will use a normal model.

### Check the relevant conditions to ensure that model assumptions are met.

* Random
    - We have no information about how these samples were obtained. We hope the 126 female patients and 79 male patients are representative of other Danish patients with malignant melanoma.

* 10%
    - We don't know exactly how many people in Denmark suffer from malignant melanoma, but we could imagine over time it's more than 1260 females and 790 males.

* Success/Failure
    - Checking the contingency table above (the one with counts), we see the numbers 28 and 98 (the successes and failures among females), and 29 and 50 (the successes and failures among males). These are all larger than 10.

Commentary: Ideally, for the success/failure condition we would like to check $n_{1} p_{1}$, $n_{1} (1 - p_{1})$, $n_{2} p_{2}$, and $n_{2} (1 - p_{2})$; however, the null makes no claim about the values of $p_{1}$ and $p_{2}$. We do the next best thing and estimate these by substituting the sample proportions $\hat{p}_{1}$ and $\hat{p}_{2}$. But $n_{1} \hat{p}_{1}$ and $n_{2} \hat{p}_{2}$ are just the raw counts of successes in each group. Likewise, $n_{1} (1 - \hat{p}_{1})$ and $n_{2} (1 - \hat{p}_{2})$ are just the raw counts of failures in each group. That's why we can just read them off the contingency table.

For a more sophisticated approach, one could also use "pooled proportions". See the [optional appendix](#pooling) for more information.


## Mechanics

### Compute the test statistic.

```{r}
status_sex_test <- prop.test(status ~ sex, data = status_sex)
status_sex_test_tidy <- tidy(status_sex_test)
status_sex_test_tidy
```

The test statistic is the difference of proportions in the sample, $\hat{p}_{1} - \hat{p}_{2}$:

```{r}
status_sex_test_tidy$estimate1 - status_sex_test_tidy$estimate2
```

Now let's compute a z-score. We first need to compute the standard error using the formula from earlier:

```{r}
SE1 <- sqrt(status_sex_test_tidy$estimate1 *
               (1 - status_sex_test_tidy$estimate1)/126 +
           status_sex_test_tidy$estimate2 * 
               (1 - status_sex_test_tidy$estimate2)/79)
SE1
```

Now that we know the SE, we can compute the z-score in the usual way:

```{r}
z1 <- (status_sex_test_tidy$estimate1 - status_sex_test_tidy$estimate2)/SE1
z1
```

Commentary: We use the `prop.test` command for this. Now that we are working with two variables, we can use the "formula" notation with the tilde that we have seen before. The only tricky thing to remember is the order of the variables. Remember that the tilde is pronounced "by", so we want to measure "status by sex" or "status grouped by sex".

As with the single proportion test, the z score is not part of the output, so we have to compute it directly.^[Ignore the test statistic from the tidy output. Under the hood, the prop.test command is doing something quite different, so this test statistic doesn't make sense in the context of a normal model.] It works the same way as the z score did for the single proportion test, but the standard error is a more complicated formula that requires a bit more typing and a bit more care.

### Report the test statistic in context (when possible).

In our sample, there is a `r 100 * (status_sex_test_tidy$estimate1 - status_sex_test_tidy$estimate2)`% difference between the rate at which women and men in Denmark die from malignant melanoma (meaning that males died at a higher rate).

The test statistic has a z score of `r z1`. The difference in proportions between the rate at which women and men in Denmark die from malignant melanoma lies 2.2 standard errors to the left of the null value.


### Plot the null distribution.

```{r}
pdist("norm", q = c(-z1, z1), invisible = TRUE)
```

Commentary: Remember that this is a two-sided test.

### Calculate the P-value.

```{r}
P1 <- 2 * pdist("norm", q = z1, plot = FALSE)
P1
```

Commentary: As in the one-proportion test, a two-sided P-value is stored in the output of the `prop.test` function:

```{r}
status_sex_test$p.value
```

Because the `prop.test` function is using a slightly different method under the hood, this P-value will not agree exactly with the one we computed. Nevertheless, they should be somewhat close and lead to the same conclusion.

### Interpret the P-value as a probability given the null.

The P-value is `r P1`. If there were truly no difference between the rate at which women and men in Denmark die from malignant melanoma, there is only a `r 100 * P1`% chance of seeing a difference in our data at least as extreme as what we saw.


## Conclusion

### State the statistical conclusion.

We reject the null hypothesis.

### State (but do not overstate) a contextually meaningful conclusion.

We have sufficient evidence to suggest that there is a difference between the rate at which women and men in Denmark die from malignant melanoma.

### Identify the possibility of either a Type I or Type II error and state what making such an error means in the context of the hypotheses.

If we have made a Type I error, then there would actually be no difference between the rate at which women and men in Denmark die from malignant melanoma, but our samples showed a significant difference.


## Confidence interval

### Check the relevant conditions to ensure that model assumptions are met.

None of the conditions have changed, so they don't need to be rechecked.

### Calculate the confidence interval.

```{r}
status_sex_test_tidy$conf.low
```

```{r}
status_sex_test_tidy$conf.high
```

### State (but do not overstate) a contextually meaningful interpretation.

We are 95% confident that the true difference between the rate at which women and men die from malignant melanoma is captured in the interval (`r 100 * status_sex_test_tidy$conf.low`%, `r 100 * status_sex_test_tidy$conf.high`%). (This difference is measured by calculating female minus male.)

Commentary: Note the addition of that last sentence. If you are looking at a confidence interval for a difference, you must indicate the direction of the difference. Without that, we would know that there was a difference, but we would have no idea whether women or men die more from malignant melanoma. Once we know that we are subtracting female minus male, then given the values are negative, we can infer that males die from malignant melanoma more often than females---at least according to this confidence interval.

### If running a two-sided test, explain how the confidence interval reinforces the conclusion of the hypothesis test.

The confidence interval does not contain the null value of zero. Since zero is not a plausible value for the true difference between the rate at which women and men die from malignant melanoma, it makes sense that we rejected the null hypothesis.


## Inference using summary statistics

In the previous example, we had access to the actual data frame. In some situations, you are not given the data; rather, all you have are summary statistics about the data. This certainly happens with homework problems from a textbook, but it can happen in "real life" too. If you're reading a research article, you will rarely have access to the original data used in the analysis. All you can see is what the researchers report in their paper. Depending on what kind of information you have, there are a couple of different ways of handling inference.

### Method 1

You may just have a summary of the total number of successes and failures. In our melanoma example, among the females, 28 died from melanoma and 98 died from other causes, and among the males, 29 died from melanoma and 50 died from other causes. If that's all we know, we can run the `prop.test` command as follows:

```{r}
status_sex_test_count <- prop.test(c(28, 29), n = c(126, 79))
status_sex_test_count_tidy <- tidy(status_sex_test_count)
status_sex_test_count_tidy
```

Once this is done (in the step "Compute and report the test statistic"), all remaining steps of the rubric stay exactly the same except that you'll use `status_sex_test_count_tidy` instead of `status_sex_test_tidy`.

### Method 2

If you are given the percentages of successes and/or failures in your data, you'll have to convert them to whole number totals. You might be told that of the 126 females, 22.2% died from  melanoma, and of the 79 males, 36.7% died from melanoma. In that case, we can run the `prop.test` command as follows:

```{r}
status_sex_test_prop <- prop.test(round(c(126*0.222, 79*0.367)),
                                       n = c(126, 79))
status_sex_test_prop_tidy <- tidy(status_sex_test_prop)
status_sex_test_prop_tidy
```

Once this is done (in the step "Compute the test statistic"), all remaining steps of the rubric stay exactly the same except that you'll use `status_sex_test_prop_tidy` instead of `status_sex_test_tidy`.


## Your turn

Go through the rubric to determine if females and males in Denmark who are diagnosed with malignant melanoma suffer from ulcerated tumors at different rates.

The rubric outline is reproduced below. You may refer to the worked example above and modify it accordingly. Remember to strip out all the commentary. That is just exposition for your benefit in understanding the steps, but is not meant to form part of the formal inference process.

Another word of warning: the copy/paste process is not a substitute for your brain. You will often need to modify more than just the names of the data frames and variables to adapt the worked examples to your own work. Do not blindly copy and paste code without understanding what it does. And you should **never** copy and paste text. All the sentences and paragraphs you write are expressions of your own analysis. They must reflect your own understanding of the inferential process.

**Also, so that your answers here don't mess up the code chunks above, use new variable names everywhere. In particular, you should use `ulcer_sex` (instead of `status_sex`) as your data frame and `ulcer_sex_test` and `ulcer_sex_test_tidy` (instead of `status_sex_test` and `status_sex_test_tidy`) to store the results of your hypothesis test. Use the following names for your standard error, z score, and P-value: `SE2`, `z2`, and `P2`.**

##### Exploratory data analysis

###### Use data documentation (help files, code books, Google, etc.), the `str` command, and other summary functions to understand the data.

<div class = "answer">

```{r}
# Add code here to understand the data.
```

</div>

###### Prepare the data for analysis. [Not always necessary.]

<div class = "answer">

```{r}
# Add code here to prepare the data for analysis.
```

</div>

###### Make tables or plots to explore the data visually.

<div class = "answer">

```{r}
# Add code here to make tables or plots.
```

</div>


##### Hypotheses

###### Identify the sample (or samples) and a reasonable population (or populations) of interest.

<div class = "answer">

Please write up your answer here.

</div>

###### Express the null and alternative hypotheses as contextually meaningful full sentences.

<div class = "answer">

$H_{0}:$ Null hypothesis goes here.

$H_{A}:$ Alternative hypothesis goes here.

</div>

###### Express the null and alternative hypotheses in symbols (when possible).

<div class = "answer">

$H_{0}: math$

$H_{A}: math$

</div>


##### Model

###### Identify the sampling distribution model.

<div class = "answer">

Please write up your answer here.

</div>

###### Check the relevant conditions to ensure that model assumptions are met.

<div class = "answer">

Please write up your answer here. (Some conditions may require R code as well.)

</div>


##### Mechanics

###### Compute the test statistic.

<div class = "answer">

```{r}
# Add code here to compute the test statistic.
```

</div>

###### Report the test statistic in context (when possible).

<div class = "answer">

Please write up your answer here.

</div>

###### Plot the null distribution.

<div class = "answer">

```{r}
# Add code here to plot the null distribution.
```

</div>

###### Calculate the P-value.

<div class = "answer">

```{r}
# Add code here to calculate the P-value.
```

</div>

###### Interpret the P-value as a probability given the null.

<div class = "answer">

Please write up your answer here.

</div>


##### Conclusion

###### State the statistical conclusion.

<div class = "answer">

Please write up your answer here.

</div>

###### State (but do not overstate) a contextually meaningful conclusion.

<div class = "answer">

Please write up your answer here.

</div>

###### Identify the possibility of either a Type I or Type II error and state what making such an error means in the context of the hypotheses.

<div class = "answer">

Please write up your answer here.

</div>


##### Confidence interval

###### Check the relevant conditions to ensure that model assumptions are met.

<div class = "answer">

Please write up your answer here. (Some conditions may require R code as well.)

</div>

###### Calculate the confidence interval.

<div class = "answer">

```{r}
# Add code here to calculate the confidence interval.
```

</div>

###### State (but do not overstate) a contextually meaningful interpretation.

<div class = "answer">

Please write up your answer here.

</div>

###### If running a two-sided test, explain how the confidence interval reinforces the conclusion of the hypothesis test.

<div class = "answer">

Please write up your answer here.

</div>


## Optional appendix: Pooling {#pooling}

Earlier, we mentioned that that we cannot calculate the "true" standard error directly because the null hypothesis does not give us $p_{1}$ and $p_{2}$. (The null only addresses the value of the difference $p_{1} - p_{2}$.) We dealt with this by simply substituting $\hat{p}_{1}$ for $p_{1}$ and $\hat{p}_{2}$ for $p_{2}$.

There is, however, one assumption from the null we can still salvage that will improve our test. Since the null hypothesis assumes that the two groups are the same, let's compute a single overall success rate for both samples together. In other words, if the two groups aren't different, let's just pool them into one single group and calculate the successes for the whole group.

This is called a *pooled proportion*. It's straightforward to compute: just take the total number of successes in both groups and divide by the total size of both groups. Here is the formula:

$$\hat{p}_{pooled} = \frac{successes_{1} + successes_{2}}{n_{1} + n_{2}}.$$

Occasionally, we are not given the raw number of successes in each group, but rather, the proportion of successes in each group, $\hat{p}_{1}$ and $\hat{p}_{2}$. The simple fix is to recompute the raw count of successes as $n_{1} \hat{p}_{1}$ and $n_{2} \hat{p}_{2}$. Here is what it looks like in the formula:

$$\hat{p}_{pooled} = \frac{n_{1} \hat{p}_{1} + n_{2} \hat{p}_{2}}{n_{1} + n_{2}}.$$
The normal model can still have a mean of $p_{1} - p_{2}$. (We usually assume this is 0 in the null hypothesis.) But its standard error will use the pooled proportion:

$$N\left( p_{1} - p_{2}, \sqrt{\frac{\hat{p}_{pooled} (1 - \hat{p}_{pooled})}{n_{1}} + \frac{\hat{p}_{pooled} (1 - \hat{p}_{pooled})}{n_{2}}} \right).$$

Not only can we use the pooled proportion in the standard error, but in fact we can use it anywhere we assume the null. For example, the success/failure condition is also subject to the assumption of the null, so we could use the pooled proportion there too.

For a confidence interval, things are different. There is no null hypothesis in effect while computing a confidence interval, so there is no assumption that would justify pooling.

The standard error in the one-proportion interval is $\sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}$, which just substitutes $\hat{p}$ for $p$. We do the same for the standard error in the two-proportion case:

$$SE = \sqrt{\frac{\hat{p}_{1} (1 - \hat{p}_{1})}{n_{1}} + \frac{\hat{p}_{2} (1 - \hat{p}_{2})}{n_{2}}}.$$
